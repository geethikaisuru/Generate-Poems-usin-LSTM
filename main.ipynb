{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' To run on GPU Select 1, to Run on CPU select -1'''\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from numba import cuda\\n\\ndevice = cuda.get_current_device()\\nattribs = [s for s in dir(device) if s.isupper()]\\n\\nfor attr in attribs:\\n    print(attr, '=', getattr(device, attr))\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from numba import cuda\n",
    "\n",
    "device = cuda.get_current_device()\n",
    "attribs = [s for s in dir(device) if s.isupper()]\n",
    "\n",
    "for attr in attribs:\n",
    "    print(attr, '=', getattr(device, attr))\n",
    "'''\n",
    "\n",
    "'''from numba import cuda\n",
    "\n",
    "device = cuda.get_current_device()\n",
    "gpu_name = device.name.decode('utf-8')\n",
    "print(\"GPU Name:\", gpu_name)'''\n",
    "\n",
    "'''device = cuda.get_current_device()\n",
    "attribs = [s for s in dir(device) if s.isupper()]\n",
    "\n",
    "for attr in attribs:\n",
    "    print(attr, '=', getattr(device, attr))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "text = open(filepath, 'rb').read().decode(encoding = 'utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[150000:750000]\n",
    "characters = sorted(set(text))\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "next_characters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_characters.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)),dtype= np.bool_ )\n",
    "y = np.zeros((len(sentences), len(characters)), dtype= np.bool_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sentence in enumerate(sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        x[i, t, char_to_index[character]] = 1\n",
    "    y[i, char_to_index[next_characters[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape = (SEQ_LENGTH, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer = RMSprop(lr=0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:1'):\n",
    "    model.fit(x, y, batch_size = 256, epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 51s 63ms/step - loss: 1.9984\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 48s 62ms/step - loss: 1.6025\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 48s 61ms/step - loss: 1.5232\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 48s 61ms/step - loss: 1.4794\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 48s 61ms/step - loss: 1.4525\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 1.4318\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 48s 61ms/step - loss: 1.4145\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 47s 61ms/step - loss: 1.4020\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 48s 62ms/step - loss: 1.3905\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 49s 62ms/step - loss: 1.3805\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 49s 63ms/step - loss: 1.3741\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 49s 63ms/step - loss: 1.3654\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 49s 63ms/step - loss: 1.3597\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 49s 63ms/step - loss: 1.3513\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 49s 62ms/step - loss: 1.3462\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 49s 63ms/step - loss: 1.3408\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 47s 61ms/step - loss: 1.3386\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 1.3312\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 48s 61ms/step - loss: 1.3252\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 48s 62ms/step - loss: 1.3221\n"
     ]
    }
   ],
   "source": [
    "'''with tf.device('/CPU'):\n",
    "    model.fit(x, y, batch_size = 256, epochs = 20)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespeares_gen.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespeares_gen.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('shakespeares_gen.model')\n",
    "model.save_weights('shakespeares_gen.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('shakespeares_gen.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probs = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text( length, temperature):\n",
    "    start_index = random.randint( 0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, character in enumerate(sentence):\n",
    "            x[0, t, char_to_index[character]] = 1\n",
    "\n",
    "        predictions = model.predict(x, verbose = 0)[0]\n",
    "        next_index = sample(predictions, temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1936\\4129162411.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "er:\n",
      "my lord, the mayor of london comes to thee.\n",
      "\n",
      "king richard iii:\n",
      "and so stay the grown of the bolingbroke.\n",
      "\n",
      "king richard iii:\n",
      "the send the compless of the world and the servance.\n",
      "\n",
      "king richard iii:\n",
      "the send the send the send to the complious son\n",
      "is provent of the servant of the mark to thee.\n",
      "\n",
      "king richard iii:\n",
      "and thou should the man of\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU'):\n",
    "    print(generate_text(300,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1936\\4129162411.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ickness that i have;\n",
      "and thy unkindness with here as a wound\n",
      "and what see the statter and most thou must but of my lord.\n",
      "\n",
      "nor many and as my husband,\n",
      "and have servantge of the blass of the ground\n",
      "should no state the way but a i repose sen.\n",
      "\n",
      "king richard iii:\n",
      "and ludy the must to the houses, and the rest;\n",
      "and should the but no pity the cam\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU'):\n",
    "    print(generate_text(300,0.6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
